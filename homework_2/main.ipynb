{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DU - Domaci 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ay1ta_D9ZSWk",
        "8KBLvwJ-ZjFU",
        "wJlLELvehcqK",
        "Px23xt5fZc4X",
        "LMapfZlQIFBT",
        "fVj4hs_gixAC"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1f7109f6c804d19b4d1297a549fbcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9acaf5c63eb4152b8b852ff78719b9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5009f292edb411fbd3d18982cb6b113",
              "IPY_MODEL_65fb4d3eae234c63b1d8a1824fec4f3d"
            ]
          }
        },
        "e9acaf5c63eb4152b8b852ff78719b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5009f292edb411fbd3d18982cb6b113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_733ca83a85554a69aa7251f1013d12da",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4c0d64c960a4be2900e65448c615d5a"
          }
        },
        "65fb4d3eae234c63b1d8a1824fec4f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8a4efb96481427ea1e88ae037fc3d8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:28&lt;00:00, 9.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb7f7fd9e54a404f8c178bf144ce16e7"
          }
        },
        "733ca83a85554a69aa7251f1013d12da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4c0d64c960a4be2900e65448c615d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8a4efb96481427ea1e88ae037fc3d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb7f7fd9e54a404f8c178bf144ce16e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt3AJfUDQTqc"
      },
      "source": [
        "function ConnectButton() {\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton, 60000);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-1U6c2WQhe6"
      },
      "source": [
        "path_root = '/content/drive/My Drive/Colab Notebooks/DU/'\n",
        "path_train = path_root + 'data/Corona_NLP_train.csv'\n",
        "path_test = path_root + 'data/Corona_NLP_test.csv'\n",
        "path_models = path_root + 'models/'\n",
        "path_logs = 'logs/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxMekK3h2cz"
      },
      "source": [
        "!rm -rf '{path_models}' '{path_logs}'\n",
        "!mkdir '{path_models}' '{path_logs}'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7VGNYrjzun"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay1ta_D9ZSWk"
      },
      "source": [
        "### Step 1: Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP0aMGNLgnge",
        "outputId": "cdd94391-f420-427d-bd4c-b470dff05504"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 34.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 14.2MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp4Kn2W139Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21600398-d105-47d7-a5b5-a2a3498349d1"
      },
      "source": [
        "import nltk\n",
        "import html\n",
        "import unidecode\n",
        "from string import ascii_lowercase\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_text(df):\n",
        "    df['x'] = [html.unescape(x) for x in df['x_orig']]\n",
        "    df['x'] = [re.sub(r'https?://\\S+', '', x) for x in df['x']]\n",
        "    df['x'] = [re.sub(r'[^\\w\\s]|\\d+', '', x) for x in df['x']]\n",
        "    df['x'] = [re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', x) for x in df['x']]\n",
        "    df['x'] = [re.sub(r'\\s\\s+|_|\\'', ' ', x) for x in df['x']]\n",
        "    df['x'] = [x.strip().lower() for x in df['x']]\n",
        "    df['x'] = [unidecode.unidecode(x) for x in df['x']]\n",
        "\n",
        "    for c in ascii_lowercase:\n",
        "        df['x'] = [re.sub(c+'{3,}', c+c, x) for x in df['x']]\n",
        "\n",
        "    #df['x'] = [regexp_tokenize(x, '\\w+') for x in df['x']]\n",
        "    #df['x'] = [' '.join(w for w in x if not w in stopwords.words('english')) for x in df['x']]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1u93yoebV9B"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def load_csv(path):\n",
        "    df = pd.read_csv(path, encoding='latin')\n",
        "    df = df.drop(columns=['UserName', 'ScreenName', 'Location', 'TweetAt'])\n",
        "    df = df.rename(columns={'OriginalTweet':'x_orig', 'Sentiment':'y'})\n",
        "\n",
        "    df['y'] = df['y'].apply(lambda x: re.sub('Extremely ', '', x))\n",
        "\n",
        "    clean_text(df)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KBLvwJ-ZjFU"
      },
      "source": [
        "### Step 2: Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkkIbyEwxlT2"
      },
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_count = Counter(df['y'])\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.pie(y_count.values(), labels=[class_trans[x] for x in y_count.keys()], autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlnV1cuBX6P0"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "for c in classes:\n",
        "    x = df[df['y'] == class_trans[c]]['x'].to_string()\n",
        "    plt.imshow(WordCloud().generate(x))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJlLELvehcqK"
      },
      "source": [
        "### Step 3: Pipeline construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqVs2yE5h4hu"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe9ZD_KAh31Q"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNQbxB2wha9B"
      },
      "source": [
        "def run_train(config):\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    tokenizer = config['tokenizer'].from_pretrained(config['name'])\n",
        "\n",
        "    if config['token_add_special']:\n",
        "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    train = load_csv(path_train)\n",
        "\n",
        "    data_train = tokenizer.batch_encode_plus(\n",
        "        train['x'].tolist(),\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=config['token_max_length'],\n",
        "        add_special_tokens=config['token_add_special'],\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    train['y_encd'] = encoder.fit_transform(train['y'])\n",
        "\n",
        "    dataset_train = tf.data.Dataset.from_tensor_slices((\n",
        "        data_train,\n",
        "        train['y_encd'].tolist()\n",
        "    ))\n",
        "\n",
        "    args = TFTrainingArguments(\n",
        "        output_dir=path_models+config['name'],\n",
        "        num_train_epochs=config['num_epochs'],\n",
        "        per_device_train_batch_size=config['batch_size'],\n",
        "        warmup_steps=config['warmup_steps'],\n",
        "        weight_decay=config['weight_decay'],\n",
        "        logging_dir=path_logs+config['name'],\n",
        "        logging_steps=config['logging_steps'],\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='accuracy'\n",
        "    )\n",
        "\n",
        "    with args.strategy.scope():\n",
        "        model = tokenizer = config['model'].from_pretrained(\n",
        "            config['name'],\n",
        "            num_labels=config['num_labels'])\n",
        "\n",
        "    def compute_metrics(pred):\n",
        "        preds, labels = eval_pred\n",
        "        preds = preds.argmax(axis=-1)\n",
        "        return accuracy_score(labels, preds)\n",
        "\n",
        "    trainer = TFTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=dataset_train,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    model.save_pretrained(path_models+config['name'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qQ4o0PHiRr-"
      },
      "source": [
        "def run_test(config):\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    tokenizer = config['tokenizer'].from_pretrained(config['name'])\n",
        "\n",
        "    if config['token_add_special']:\n",
        "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    test = load_csv(path_test)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    test['y_encd'] = encoder.fit_transform(test['y'])\n",
        "\n",
        "    if config['model_from_tf']:\n",
        "        model = config['model'].from_pretrained(\n",
        "            path_models+config['name'],\n",
        "            num_labels=config['num_labels'],\n",
        "            from_tf=True)\n",
        "    else:\n",
        "        model = config['model'].from_pretrained(\n",
        "            path_models+config['name'],\n",
        "            num_labels=config['num_labels'])\n",
        "\n",
        "    if config['model_to_cuda']:\n",
        "        device = torch.device('cuda')\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for i, row in test.iterrows():\n",
        "        if config['tensor_type'] == 'tf':\n",
        "            inputs = tokenizer(row['x'], return_tensors='tf')\n",
        "            inputs['labels'] = tf.reshape(tf.constant(1), (-1, 1))\n",
        "            outputs = model(inputs)\n",
        "            labels = inputs['labels']\n",
        "            logits = outputs.logits\n",
        "        elif config['tensor_type'] == 'pt':\n",
        "            inputs = tokenizer(row['x'], return_tensors='pt').to(device)\n",
        "            labels = torch.tensor([row['y_encd']]).unsqueeze(0).to(device)\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "\n",
        "        y_true.append(labels)\n",
        "        y_pred.append(logits)\n",
        "\n",
        "    y_true = np.concatenate(y_true, axis=0)\n",
        "    y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "    y_pred = [encoder.classes_[np.argmax(y)] for y in y_pred]\n",
        "    y_true = [encoder.classes_[y] for y in y_true]\n",
        "\n",
        "    print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px23xt5fZc4X"
      },
      "source": [
        "### Classifier 1: Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ij0E8FsdpCZ",
        "outputId": "bda29302-6329-4235-8e1d-ab9d70bba610"
      },
      "source": [
        "%%time\n",
        "train = load_csv(path_train)\n",
        "model = Pipeline([('vectorizer', TfidfVectorizer()),\n",
        "                  ('clf', LogisticRegression(max_iter=500))])\n",
        "model.fit(train['x'], train['y'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 57s, sys: 30.5 s, total: 2min 27s\n",
            "Wall time: 2min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyD-avF5iYRL",
        "outputId": "ddf5cf33-ab48-4471-abe4-2afd77a1f6a3"
      },
      "source": [
        "%%time\n",
        "test = load_csv(path_test)\n",
        "y_pred = model.predict(test['x'])\n",
        "print(classification_report(test['y'], y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.79      0.76      0.78      1633\n",
            "     Neutral       0.69      0.58      0.63       619\n",
            "    Positive       0.77      0.84      0.80      1546\n",
            "\n",
            "    accuracy                           0.77      3798\n",
            "   macro avg       0.75      0.73      0.74      3798\n",
            "weighted avg       0.76      0.77      0.76      3798\n",
            "\n",
            "CPU times: user 10.2 s, sys: 1.32 s, total: 11.6 s\n",
            "Wall time: 12.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMapfZlQIFBT"
      },
      "source": [
        "### Classifier 2: DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2MFmdSsIDbo"
      },
      "source": [
        "config = {\n",
        "    'name': 'distilbert-base-uncased',\n",
        "    'tokenizer': AutoTokenizer,\n",
        "    'model': AutoModelForSequenceClassification,\n",
        "    'batch_size': 16,\n",
        "    'num_epochs': 5,\n",
        "    'num_labels': 3,\n",
        "    'learning_rate': 2e-5,\n",
        "    'warmup_steps': 500,\n",
        "    'weight_decay': 0.01,\n",
        "    'logging_steps': 10,\n",
        "    'token_max_length': 50,\n",
        "    'token_add_special': False,\n",
        "    'model_from_tf': False,\n",
        "    'model_to_cuda': False,\n",
        "    'tensor_type': 'tf'\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Fuoq-rkA24"
      },
      "source": [
        "%tensorboard --logdir '{path_logs}'{config['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcyZS4wyi_sQ"
      },
      "source": [
        "%%time\n",
        "run_train(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Xx-JXNjA3c"
      },
      "source": [
        "%%time\n",
        "run_test(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVj4hs_gixAC"
      },
      "source": [
        "### Classifier 3: DistilGPT2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZidHhXafKBb"
      },
      "source": [
        "config = {\n",
        "    'name': 'distilgpt2',\n",
        "    'tokenizer': AutoTokenizer,\n",
        "    'model': TFAutoModelForSequenceClassification,\n",
        "    'batch_size': 1,\n",
        "    'num_epochs': 5,\n",
        "    'num_labels': 3,\n",
        "    'learning_rate': 2e-5,\n",
        "    'warmup_steps': 500,\n",
        "    'weight_decay': 0.01,\n",
        "    'logging_steps': 10,\n",
        "    'token_max_length': 50,\n",
        "    'token_add_special': True,\n",
        "    'model_from_tf': True,\n",
        "    'model_to_cuda': True,\n",
        "    'tensor_type': 'pt'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRcHscGtkBys"
      },
      "source": [
        "%tensorboard --logdir '{path_logs}'{config['name']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXhws5BhgLzl"
      },
      "source": [
        "%%time\n",
        "run_train(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITrtlk79gN14"
      },
      "source": [
        "%%time\n",
        "run_test(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC1S4tToteJD"
      },
      "source": [
        "### temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430,
          "referenced_widgets": [
            "b1f7109f6c804d19b4d1297a549fbcf4",
            "e9acaf5c63eb4152b8b852ff78719b9e",
            "b5009f292edb411fbd3d18982cb6b113",
            "65fb4d3eae234c63b1d8a1824fec4f3d",
            "733ca83a85554a69aa7251f1013d12da",
            "e4c0d64c960a4be2900e65448c615d5a",
            "c8a4efb96481427ea1e88ae037fc3d8c",
            "eb7f7fd9e54a404f8c178bf144ce16e7"
          ]
        },
        "id": "MwD5gdletPEX",
        "outputId": "41de9c67-d45f-4c46-a601-c5c298df9fd7"
      },
      "source": [
        "config = {\n",
        "    'name': 'distilbert-base-uncased',\n",
        "    'tokenizer': AutoTokenizer,\n",
        "    'model': AutoModelForSequenceClassification,\n",
        "    'num_labels': 3,\n",
        "    'token_add_special': False,\n",
        "    'model_from_tf': False,\n",
        "    'model_to_cuda': False,\n",
        "    'tensor_type': 'tf'\n",
        "}\n",
        "\n",
        "def run_train(config):\n",
        "    tokenizer = config['tokenizer'].from_pretrained(config['name'])\n",
        "\n",
        "    if config['token_add_special']:\n",
        "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    train, test = load_csv(path_train), load_csv(path_test)\n",
        "\n",
        "    data_train = tokenizer.batch_encode_plus(\n",
        "        train['x'].tolist(),\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=50,\n",
        "        add_special_tokens=config['token_add_special'],\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    data_test = tokenizer.batch_encode_plus(\n",
        "        test['x'].tolist(),\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=50,\n",
        "        add_special_tokens=config['token_add_special'],\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    train['y_encd'] = encoder.fit_transform(train['y'])\n",
        "    test['y_encd'] = encoder.fit_transform(test['y'])\n",
        "\n",
        "    dataset_train = TensorDataset(\n",
        "        data_train['input_ids'],\n",
        "        data_train['attention_mask'],\n",
        "        torch.tensor(train['y_encd'].tolist()))\n",
        "\n",
        "    dataset_test = TensorDataset(\n",
        "        data_test['input_ids'],\n",
        "        data_test['attention_mask'],\n",
        "        torch.tensor(test['y_encd'].tolist()))\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=path_models+config['name'],\n",
        "        evaluation_strategy='steps',\n",
        "        logging_dir=path_logs+config['name'],\n",
        "        logging_steps=250,\n",
        "        fp16=True,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='accuracy'\n",
        "    )\n",
        "\n",
        "    def model_init(trial):\n",
        "        return config['model'].from_pretrained(\n",
        "            config['name'],\n",
        "            num_labels=config['num_labels'])\n",
        "\n",
        "    def data_collator(features):\n",
        "        return {\n",
        "            'input_ids': torch.stack([f[0] for f in features]),\n",
        "            'attention_mask': torch.stack([f[1] for f in features]),\n",
        "            'labels': torch.stack([f[2] for f in features])\n",
        "        }\n",
        "\n",
        "    def compute_metrics(out):\n",
        "        label_ids = out.label_ids\n",
        "        predictions = out.predictions.argmax(-1)\n",
        "        return {\n",
        "            'accuracy': accuracy_score(label_ids, predictions)\n",
        "        }\n",
        "\n",
        "    callback_stop = EarlyStoppingCallback(\n",
        "        early_stopping_patience=2,\n",
        "        early_stopping_threshold=1e-6)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        args=args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=dataset_train,\n",
        "        eval_dataset=dataset_test,\n",
        "        tokenizer=tokenizer,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[callback_stop]\n",
        "    )\n",
        "\n",
        "    best_run = trainer.hyperparameter_search(\n",
        "        n_trials=10,\n",
        "        direction='maximize',\n",
        "        backend='optuna')\n",
        "    \n",
        "    print('Best run:', best_run)\n",
        "\n",
        "    for n, v in best_run.hyperparameters.items():\n",
        "        setattr(trainer.args, n, v)\n",
        "\n",
        "    trainer.train()\n",
        "    model.save_pretrained(path_models+config['name'])\n",
        "\n",
        "run_train(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1f7109f6c804d19b4d1297a549fbcf4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m[I 2021-01-03 07:55:28,038]\u001b[0m A new study created in memory with name: no-name-1fdc2ac4-0b41-4996-846a-be499ce3cb6b\u001b[0m\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='251' max='2573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 250/2573 00:14 < 02:16, 16.97 it/s, Epoch 0.10/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.886402</td>\n",
              "      <td>0.598999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}