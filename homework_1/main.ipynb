{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DU - Domaci 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-1U6c2WQhe6"
      },
      "source": [
        "path_cwd = '/content/'\n",
        "path_logs = path_cwd + 'logs/'\n",
        "path_models = path_cwd + 'models/'\n",
        "path_root = '/content/drive/My Drive/Colab Notebooks/DU/data/'\n",
        "path_zip = path_root + 'Coronahack-Chest-XRay-Dataset.zip'\n",
        "path_unzip = path_root + 'Coronahack-Chest-XRay-Dataset/'\n",
        "path_csv = path_unzip + 'Chest_xray_Corona_Metadata.csv'\n",
        "path_train = path_unzip + 'Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/'\n",
        "path_test = path_unzip + 'Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjltyg4eJFZC"
      },
      "source": [
        "!rm -rf '{path_unzip}'\n",
        "!unzip '{path_zip}' -d '{path_unzip}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ODhUw2BMsb"
      },
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.python.util.deprecation as deprecation\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import load_model\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E66eLbgB-hY-"
      },
      "source": [
        "%load_ext tensorboard\n",
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SArxEazVFBC"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1u93yoebV9B"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, classes, shape=(64, 64)):\n",
        "        self.shape = shape\n",
        "        self.classes = classes\n",
        "        self.class_trans = {}\n",
        "        for i, c in enumerate(self.classes):\n",
        "            self.class_trans[c], self.class_trans[i] = i, c\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        df = pd.read_csv(path_csv)\n",
        "        df = df.drop(columns=['Unnamed: 0', 'Label_1_Virus_category', 'Label_2_Virus_category'])\n",
        "        df = df.rename(columns={'X_ray_image_name':'x', 'Label':'y'})\n",
        "\n",
        "        train_mask = df['Dataset_type'] == 'TRAIN'\n",
        "        self.xy_train, self.xy_test = df[train_mask], df[~train_mask]\n",
        "\n",
        "        self.xy_train['x'] = path_train + self.xy_train['x']\n",
        "        self.xy_test['x'] = path_test + self.xy_test['x']\n",
        "\n",
        "        self.y_test = self.xy_test['y'].apply(lambda x: self.class_trans[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H17w1N9dVDRf"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEzmb3pj7QwM"
      },
      "source": [
        "class Model:\n",
        "    def __init__(self, data, epochs=8, batch_size=32, l2_beta=0.01):\n",
        "        self.data = data\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.l2_beta = l2_beta\n",
        "\n",
        "\n",
        "    def build(self):\n",
        "        self.model = self._build()\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "        class_weights = class_weight.compute_class_weight('balanced', self.data.classes, self.data.xy_train['y'])\n",
        "        class_weights = dict(zip(range(len(self.data.classes)), class_weights))\n",
        "\n",
        "        callbacks = [EarlyStopping(patience=2, restore_best_weights=True), TensorBoard(path_logs)]\n",
        "\n",
        "        train_flow = self._flow(self._train_gen(), self.data.xy_train)\n",
        "        test_flow = self._flow(self._test_gen(), self.data.xy_test)\n",
        "\n",
        "        return self.model.fit_generator(\n",
        "            train_flow,\n",
        "            epochs=self.epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=test_flow,\n",
        "            class_weight=class_weights)\n",
        "\n",
        "\n",
        "    def save(self):\n",
        "        self.model.save(path_models + type(self).__name__)\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        self.model = load_model(path_models + type(self).__name__)\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        test_flow = self._flow(self._test_gen(), self.data.xy_test)\n",
        "        y_pred = self.model.predict_generator(test_flow) > 0.5\n",
        "\n",
        "        cr = classification_report(self.data.y_test, y_pred, target_names=self.data.classes)\n",
        "        print(cr)\n",
        "\n",
        "        cm = confusion_matrix(self.data.y_test, y_pred)\n",
        "        plt.matshow(cm)\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.show()\n",
        "\n",
        "        x_test, y_test = self.data.xy_test['x'].values.tolist(), self.data.xy_test['y'].values.tolist()\n",
        "        y_pred = [self.data.class_trans[y] for y in y_pred.flatten()]\n",
        "\n",
        "        return x_test, y_test, y_pred\n",
        "\n",
        "\n",
        "    def _train_gen(self):\n",
        "        return ImageDataGenerator(\n",
        "            rotation_range=15,\n",
        "            zoom_range=0.25,\n",
        "            rescale=1.0/255.0)\n",
        "\n",
        "\n",
        "    def _test_gen(self):\n",
        "        return ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "\n",
        "    def _flow(self, generator, dataframe):\n",
        "        return generator.flow_from_dataframe(\n",
        "            dataframe=dataframe,\n",
        "            x_col='x',\n",
        "            y_col='y',\n",
        "            target_size=self.data.shape,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Bzy3HjU_UZ"
      },
      "source": [
        "# Specific nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBH54ARs9qMb"
      },
      "source": [
        "class MyLeNet5(Model):\n",
        "    def _build(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, 5, activation='relu', input_shape=self.data.shape + (3, )))\n",
        "        model.add(MaxPool2D(2))\n",
        "        model.add(Conv2D(48, 5, padding='valid', activation='relu'))\n",
        "        model.add(MaxPool2D(2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, activation='selu',\n",
        "                        kernel_initializer='lecun_normal',\n",
        "                        kernel_regularizer=regularizers.l2(self.l2_beta)))\n",
        "        model.add(Dense(84, activation='selu',\n",
        "                        kernel_initializer='lecun_normal',\n",
        "                        kernel_regularizer=regularizers.l2(self.l2_beta)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "\n",
        "class MyAlexNet(Model):\n",
        "    def _build(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, 5, strides=4, activation='relu', input_shape=self.data.shape + (3, )))\n",
        "        model.add(MaxPool2D(3, 2))\n",
        "        model.add(Conv2D(256, 5, padding='same', activation='relu'))\n",
        "        model.add(MaxPool2D(3, 2))\n",
        "        model.add(Conv2D(384, 3, padding='same', activation='relu'))\n",
        "        model.add(Conv2D(384, 3, padding='same', activation='relu'))\n",
        "        model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
        "        model.add(MaxPool2D(3, 2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096,\n",
        "                        activation='selu',\n",
        "                        kernel_initializer='lecun_normal',\n",
        "                        kernel_regularizer=regularizers.l2(self.l2_beta)))\n",
        "        model.add(Dense(4096,\n",
        "                        activation='selu',\n",
        "                        kernel_initializer='lecun_normal',\n",
        "                        kernel_regularizer=regularizers.l2(self.l2_beta)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "\n",
        "class MyResNet50(Model):\n",
        "    def _build(self):\n",
        "        base = ResNet50(include_top=False, input_shape=self.data.shape + (3, ))\n",
        "        base.trainable = False\n",
        "        model = Sequential()\n",
        "        model.add(base)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "\n",
        "class MyVGG16(Model):\n",
        "    def _build(self):\n",
        "        base = VGG16(include_top=False, input_shape=self.data.shape + (3, ))\n",
        "        base.trainable = False\n",
        "        model = Sequential()\n",
        "        model.add(base)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOFH0idVHVY"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI8pcVpbErmu"
      },
      "source": [
        "class Ensemble:\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "        for i, model in enumerate(self.models):\n",
        "            model.build()\n",
        "            history = model.fit()\n",
        "            self._plot(history, len(self.models), i)\n",
        "            model.save()\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        preds = []\n",
        "\n",
        "        for model in self.models:\n",
        "            model.load()\n",
        "            preds.append(model.predict())\n",
        "\n",
        "        return preds\n",
        "\n",
        "\n",
        "    def _plot(self, history, model_total, model_index):\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(model_total, 2, 2 * model_index + 1)\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'])\n",
        "\n",
        "        plt.subplot(model_total, 2, 2 * model_index + 2)\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoCOmKnfVJi9"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg3YG8ICniDf"
      },
      "source": [
        "!rm -rf '{path_logs}' '{path_models}'\n",
        "!mkdir '{path_logs}' '{path_models}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_fPIbHfGUzV",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "dataset = Dataset(['Normal', 'Pnemonia'])\n",
        "dataset.load()\n",
        "\n",
        "models = []\n",
        "models.append(MyLeNet5(dataset))\n",
        "models.append(MyAlexNet(dataset))\n",
        "models.append(MyResNet50(dataset))\n",
        "models.append(MyVGG16(dataset))\n",
        "\n",
        "ensemble = Ensemble(models)\n",
        "ensemble.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-wzGsKr4st"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "print(plt.rcParams.get('figure.figsize')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lapdxdMP1Jf2",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "%tensorboard --logdir '{path_logs}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9_2yUcTVNKU"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQYSMbYF0nZg"
      },
      "source": [
        "%%time\n",
        "\n",
        "dataset = Dataset(['Normal', 'Pnemonia'])\n",
        "dataset.load()\n",
        "\n",
        "models = []\n",
        "models.append(MyLeNet5(dataset))\n",
        "models.append(MyAlexNet(dataset))\n",
        "models.append(MyResNet50(dataset))\n",
        "models.append(MyVGG16(dataset))\n",
        "\n",
        "ensemble = Ensemble(models)\n",
        "preds = ensemble.predict()\n",
        "\n",
        "for pred in np.transpose(preds):\n",
        "    counts = Counter([p for p in pred[2]])\n",
        "    p, prob = counts.most_common(1)[0][0], sum(counts.values())\n",
        "    print(\"Predicted={}\\tActual={}\\tProbability={}/{}\".format(p, pred[1][0], counts[p], prob))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}